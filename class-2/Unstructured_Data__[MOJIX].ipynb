{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unstructured_Data_ [MOJIX].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCLQddADEfOq"
      },
      "source": [
        "# Extracción de datos para fuentes no estructuradas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-64herWEnxk"
      },
      "source": [
        "# Caso 1\n",
        "\n",
        "Extracción de noticias/artículos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc_BwRHe9chv"
      },
      "source": [
        "# Vamos a instalar una de las librerías que nos permiten obtener el contenido \n",
        "# de las noticias de una página web\n",
        "# https://pypi.org/project/goose3/\n",
        "!pip install goose3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU8HhQSn8vDZ"
      },
      "source": [
        "# Importamos la librería\n",
        "from goose3 import Goose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AVzKSk-9g5V"
      },
      "source": [
        "# Definamos la url a partir de la cual deseamos extraer la noticia\n",
        "url_noticia = 'https://cnnespanol.cnn.com/2019/09/10/alerta-incendios-en-bolivia-consumen-dos-millones-de-hectareas/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th_adPZT_UpX"
      },
      "source": [
        "# Inicializamos la librería, especificando el lenguaje en la que se encuentra el\n",
        "# contenido del artículo\n",
        "g = Goose({'target_language':'es', 'use_meta_language': False})\n",
        "# Extraemos el contenido de la url y almacenamos el contenido en la variable article\n",
        "article = g.extract(url=url_noticia)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8pZSZZtF0f8"
      },
      "source": [
        "# Veamos el título de la noticia\n",
        "print (\"******* Título de la noticia: ******* \\n\")\n",
        "article.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P7TkfumFpfW"
      },
      "source": [
        "# Veamos el contenido de la noticia extraída\n",
        "# Ya que la noticia puede ser muy larga, vamos a limitar el número de caracteres a desplegar\n",
        "max_chars_to_show = 300 \n",
        "\n",
        "print (\"******* Contenido de la noticia: ******* \\n\")\n",
        "print(article.cleaned_text[:max_chars_to_show])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNQZup7vAXQL"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "# from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGyE7UGNAO7M"
      },
      "source": [
        "# Creamos el primer wordcloud a partir del texto que hemos obtenido\n",
        "wordcloud = WordCloud(max_words=200, background_color=\"white\").generate(article.cleaned_text)\n",
        "plt.figure(1, figsize=(12, 12))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0FIwyoXHZLA"
      },
      "source": [
        "# En el worcloud previo generado, vemos que existen palabras \"conectoras\" que \n",
        "# se repiten con más frecuencia que el resto.\n",
        "# Es necesario aplicar un procedimiento para remover los \"stopwords\"\n",
        "# https://countwordsfree.com/stopwords/spanish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bewbK_KhCLyY"
      },
      "source": [
        "# Importamos las librerías y utilitarios necesarios para procesar el texto del artículo\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd2okqJgHzGn"
      },
      "source": [
        "# Vamos a generar el listado de Stopwords de la librería que debemos usar para \n",
        "stopwords_esp = stopwords.words('spanish')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT__lpmADWHB"
      },
      "source": [
        "# Veamos las contenido inicial de los stopwords\n",
        "stopwords_esp[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spHgr5AJpnZ"
      },
      "source": [
        "# Puedes adicionar a la lista las palabras propias del contexto de la noticia.. no relevantes que \n",
        "# no deberían mostrarse en el wordcloud\n",
        "stopwords_propias = ['CNN', 'Español']\n",
        "stopwords_esp.extend(stopwords_propias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC9IsyteG7-V"
      },
      "source": [
        "# Volvamos a crear el wordcloud, pero esta vez, vamos a remover las stopwords\n",
        "wordcloud = WordCloud(max_words=100, background_color=\"white\", stopwords=stopwords_esp).generate(article.cleaned_text)\n",
        "plt.figure(1, figsize=(12, 12))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZRJAF1qKTnI"
      },
      "source": [
        "# Caso 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwkXBrZkKVbK"
      },
      "source": [
        "# Crea un archivo que contengo el texto (plano) que deseas analizar\n",
        "archivo_nombre = 'my_texto.txt'\n",
        "# Vamos a leer el contenido del archivo y almacenaremos el texto del archivo en la \n",
        "# variable mi_texto\n",
        "f = open(archivo_nombre, \"r\")\n",
        "mi_texto = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5xGvccILNp7"
      },
      "source": [
        "# Imprimimos el contenido de la variable \"mi_texto\"\n",
        "mi_texto[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ1pmexyLRqa"
      },
      "source": [
        "# Volvamos a crear el wordcloud a partir del texto introducido.\n",
        "wordcloud = WordCloud(max_words=100, background_color=\"white\", stopwords=stopwords_esp).generate(mi_texto)\n",
        "plt.figure(1, figsize=(12, 12))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9HPMwVAMxAd"
      },
      "source": [
        "# Caso 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pxbuE9GM0PY"
      },
      "source": [
        "!pip install feedparser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFmocrrIM-1Z"
      },
      "source": [
        "import feedparser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkWppwPkOosG"
      },
      "source": [
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT6VhPDFwV-I"
      },
      "source": [
        "# https://www.paginasiete.bo/rss/\n",
        "\n",
        "FEED_URL='https://www.paginasiete.bo/rss/feed.html?r=91'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2HH4D7Bw7f2"
      },
      "source": [
        "fp = feedparser.parse(FEED_URL)\n",
        "\n",
        "for e in fp.entries:\n",
        "    print(\"-------------------------\")\n",
        "    print(remove_tags(e.title))\n",
        "    # print(e.links[0].href)\n",
        "    print(remove_tags(e.content[0].value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rhJSl6YNhFA"
      },
      "source": [
        "FEED_URL = \"https://www.lostiempos.com/rss/ultimas\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yssviQ4OLUxJ"
      },
      "source": [
        "fp = feedparser.parse(FEED_URL)\n",
        "\n",
        "for e in fp.entries:\n",
        "    print(\"-------------------------\")\n",
        "    print(remove_tags(e.title))\n",
        "    # print(e.links[0].href)\n",
        "    print(remove_tags(e.summary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-Pupb1GIBs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}